{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm  # Add this\n",
        "# import time  # Optional\n",
        "\n",
        "API_KEY = \"AIzaSyD5ELJ03IEUL98JtLBnSN_IKMOHfxOB9Jw\"\n",
        "\n",
        "# Function to get directions\n",
        "def get_route_data(start_lat, start_lng, end_lat, end_lng):\n",
        "    url = f\"https://maps.googleapis.com/maps/api/directions/json?origin={start_lat},{start_lng}&destination={end_lat},{end_lng}&alternatives=true&departure_time=now&key={API_KEY}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    routes = []\n",
        "    if \"routes\" in data:\n",
        "        for route in data[\"routes\"]:\n",
        "            try:\n",
        "                distance = route[\"legs\"][0][\"distance\"][\"value\"]\n",
        "                duration = route[\"legs\"][0][\"duration\"][\"value\"]\n",
        "                traffic_duration = route[\"legs\"][0].get(\"duration_in_traffic\", {}).get(\"value\", duration)\n",
        "                steps = len(route[\"legs\"][0][\"steps\"])\n",
        "                routes.append([\n",
        "                    start_lat, start_lng, end_lat, end_lng,\n",
        "                    distance, duration, traffic_duration, steps\n",
        "                ])\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error parsing route: {e}\")\n",
        "    return routes\n",
        "\n",
        "# üåê South Indian cities with full AP + TS\n",
        "south_india_cities = {\n",
        "    # Karnataka\n",
        "    \"Bangalore\": (12.9716, 77.5946),\n",
        "    \"Mysore\": (12.2958, 76.6394),\n",
        "    \"Mangalore\": (12.9141, 74.8560),\n",
        "\n",
        "    # Tamil Nadu\n",
        "    \"Chennai\": (13.0827, 80.2707),\n",
        "    \"Coimbatore\": (11.0168, 76.9558),\n",
        "    \"Madurai\": (9.9252, 78.1198),\n",
        "    \"Tirunelveli\": (8.7139, 77.7567),\n",
        "    \"Salem\": (11.6643, 78.1460),\n",
        "    \"Tiruchirappalli\": (10.7905, 78.7047),\n",
        "\n",
        "    # Kerala\n",
        "    \"Thiruvananthapuram\": (8.5241, 76.9366),\n",
        "    \"Kochi\": (9.9312, 76.2673),\n",
        "    \"Kozhikode\": (11.2588, 75.7804),\n",
        "\n",
        "    # Puducherry\n",
        "    \"Puducherry\": (11.9139, 79.8145),\n",
        "\n",
        "    # Telangana (TS)\n",
        "    \"Hyderabad\": (17.3850, 78.4867),\n",
        "    \"Warangal\": (17.9784, 79.5941),\n",
        "    \"Nizamabad\": (18.6725, 78.0941),\n",
        "    \"Khammam\": (17.2473, 80.1514),\n",
        "    \"Karimnagar\": (18.4386, 79.1288),\n",
        "    \"Mahbubnagar\": (16.7445, 77.9844),\n",
        "    \"Adilabad\": (19.6667, 78.5333),\n",
        "    \"Ramagundam\": (18.7557, 79.4748),\n",
        "\n",
        "    # Andhra Pradesh (AP)\n",
        "    \"Vijayawada\": (16.5062, 80.6480),\n",
        "    \"Visakhapatnam\": (17.6868, 83.2185),\n",
        "    \"Guntur\": (16.3067, 80.4365),\n",
        "    \"Tirupati\": (13.6288, 79.4192),\n",
        "    \"Rajahmundry\": (17.0005, 81.8040),\n",
        "    \"Kakinada\": (16.9891, 82.2475),\n",
        "    \"Nellore\": (14.4426, 79.9865),\n",
        "    \"Kadapa\": (14.4775, 78.8231),\n",
        "    \"Anantapur\": (14.6819, 77.6006),\n",
        "    \"Ongole\": (15.5057, 80.0499),\n",
        "    \"Srikakulam\": (18.2969, 83.8966),\n",
        "    \"Chittoor\": (13.2172, 79.1003),\n",
        "}\n",
        "\n",
        "# Other major Indian cities (interconnectivity)\n",
        "pan_india_metros = {\n",
        "    \"Mumbai\": (19.0760, 72.8777),\n",
        "    \"Delhi\": (28.7041, 77.1025),\n",
        "    \"Kolkata\": (22.5726, 88.3639),\n",
        "    \"Ahmedabad\": (23.0225, 72.5714),\n",
        "    \"Pune\": (18.5204, 73.8567),\n",
        "    \"Nagpur\": (21.1458, 79.0882),\n",
        "    \"Lucknow\": (26.8467, 80.9462),\n",
        "    \"Jaipur\": (26.9124, 75.7873),\n",
        "    \"Guwahati\": (26.1445, 91.7362),\n",
        "    \"Bhubaneswar\": (20.2961, 85.8245)\n",
        "}\n",
        "\n",
        "# Generate South-South combinations\n",
        "south_pairs = list(combinations(south_india_cities.items(), 2))\n",
        "\n",
        "# Generate South ‚Üî Pan-India interconnectivity\n",
        "connectivity_pairs = [((s_name, s_coords), (m_name, m_coords))\n",
        "                      for s_name, s_coords in south_india_cities.items()\n",
        "                      for m_name, m_coords in pan_india_metros.items()]\n",
        "\n",
        "# Combine all routes\n",
        "all_city_pairs = south_pairs + connectivity_pairs\n",
        "\n",
        "# Data Collection with tqdm\n",
        "all_routes = []\n",
        "for (src_name, (start_lat, start_lng)), (dst_name, (end_lat, end_lng)) in tqdm(all_city_pairs, desc=\"üöó Fetching Routes\"):\n",
        "    try:\n",
        "        routes = get_route_data(start_lat, start_lng, end_lat, end_lng)\n",
        "        all_routes.extend(routes)\n",
        "        # time.sleep(0.5)  # Optional: reduce risk of quota issues\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {src_name} to {dst_name} ‚Äî {e}\")\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(all_routes, columns=[\n",
        "    \"start_lat\", \"start_lng\", \"end_lat\", \"end_lng\",\n",
        "    \"distance\", \"duration\", \"traffic_duration\", \"steps\"\n",
        "])\n",
        "df.to_csv(\"expanded_routes_data.csv\", index=False)\n",
        "print(\"‚úÖ Data collection complete! Saved as expanded_routes_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVtZGgK4QsUM",
        "outputId": "9cea0388-5d8d-47cf-e9b1-2b42c3d675a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üöó Fetching Routes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 858/858 [07:46<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data collection complete! Saved as expanded_routes_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"expanded_routes_data.csv\")\n",
        "\n",
        "# Feature Engineering\n",
        "df[\"distance_km\"] = df[\"distance\"] / 1000\n",
        "df[\"duration_min\"] = df[\"duration\"] / 60\n",
        "df[\"traffic_duration_min\"] = df[\"traffic_duration\"] / 60\n",
        "\n",
        "# Select features and labels\n",
        "X = df[[\"distance_km\", \"steps\"]]  # Features\n",
        "y = df[\"traffic_duration_min\"]  # Target: Travel time with traffic\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define XGBoost model\n",
        "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\"n_estimators\": [100, 200], \"learning_rate\": [0.1, 0.05], \"max_depth\": [5, 7]}\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring=\"neg_mean_absolute_error\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Train best model\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"Model Performance: MAE = {mae:.2f}, RMSE = {rmse:.2f}\")\n",
        "\n",
        "# Save the trained model\n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(\"Model saved as model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5ZNgvpNQvZc",
        "outputId": "c63d463e-eecb-47d8-c24d-5928a1255b95"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: MAE = 60.57, RMSE = 95.51\n",
            "Model saved as model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HrvvEPWYCqD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
